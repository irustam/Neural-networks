{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "1. Попробуйте обучить, нейронную сеть на Keras(рассмотренную на уроке) на датасете MNIST с другими параметрами. Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(edgeitems=20, linewidth=1000, formatter=dict(float=lambda x: \"%.3g\" % x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13  25 100 122   7   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  33 151 208 252 252 252 146   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  40 152 244 252 253 224 211 252 232  40   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  15 152 239 252 252 252 216  31  37 252 252  60   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  96 252 252 252 252 217  29   0  37 252 252  60   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 181 252 252 220 167  30   0   0  77 252 252  60   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  26 128  58  22   0   0   0   0 100 252 252  60   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 157 252 252  60   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 110 121 122 121 202 252 194   3   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  10  53 179 253 253 255 253 253 228  35   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   5  54 227 252 243 228 170 242 252 252 231 117   6   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   6  78 252 252 125  59   0  18 208 252 252 252 252  87   7   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   5 135 252 252 180  16   0  21 203 253 247 129 173 252 252 184  66  49  49   0   0   0]\n",
      " [  0   0   0   0   0   3 136 252 241 106  17   0  53 200 252 216  65   0  14  72 163 241 252 252 223   0   0   0]\n",
      " [  0   0   0   0   0 105 252 242  88  18  73 170 244 252 126  29   0   0   0   0   0  89 180 180  37   0   0   0]\n",
      " [  0   0   0   0   0 231 252 245 205 216 252 252 252 124   3   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 207 252 252 252 252 178 116  36   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  13  93 143 121  23   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c681dc41c8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(train_images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(train_images, train_labels, neurons, internal_layers, epochs, verb_param, metric='accuracy'):\n",
    "    # Build the model.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_shape=(784,)))\n",
    "    for i in range(internal_layers):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    # Compile the model.\n",
    "    model.compile(\n",
    "      optimizer='adam',\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=[metric],\n",
    "    )\n",
    "    \n",
    "    # Train the model.\n",
    "    model.fit(\n",
    "      train_images,\n",
    "      to_categorical(train_labels),\n",
    "      epochs=epochs,\n",
    "      batch_size=32,\n",
    "      verbose=verb_param\n",
    "    )\n",
    "\n",
    "    # Evaluate the model.\n",
    "    model.evaluate(\n",
    "      test_images,\n",
    "      to_categorical(test_labels)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3617 - accuracy: 0.8917\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1814 - accuracy: 0.9445\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1391 - accuracy: 0.9565\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1154 - accuracy: 0.9635\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1004 - accuracy: 0.9692\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9637\n"
     ]
    }
   ],
   "source": [
    "model = create_model(train_images, train_labels, neurons=64, internal_layers=1, epochs=5, verb_param=1, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6]\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk.\n",
    "# model.save_weights('model.h5')\n",
    "\n",
    "# Load the model from disk later using:\n",
    "# model.load_weights('model.h5')\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:55])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:55]) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Протестируем разные кол-ва нейронов с слоях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нейронов: 32\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9500\n",
      "Нейронов: 64\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9635\n",
      "Нейронов: 128\n",
      "313/313 [==============================] - 0s 935us/step - loss: 0.0980 - accuracy: 0.9696\n",
      "Нейронов: 256\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0825 - accuracy: 0.9732\n",
      "Нейронов: 384\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "for n in [32, 64, 128, 256, 384]:\n",
    "    print('Нейронов:', n)\n",
    "    create_model(train_images, train_labels, neurons=n, internal_layers=1, epochs=5, verb_param=0, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прослеживается реальная зависимость между кол-вом нейронов и значением метрики качества модели. Но, до определенных пределов. На уровне 256 нейронов было максимальное значение метрики. Дальнейшее увеличение кол-ва нейронов только уменьшило значение метрики качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Протестируем разные кол-ва внутренних слоев сетки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во слоев: 1\n",
      "313/313 [==============================] - 0s 913us/step - loss: 0.1081 - accuracy: 0.9667\n",
      "Кол-во слоев: 2\n",
      "313/313 [==============================] - 0s 860us/step - loss: 0.1204 - accuracy: 0.9615\n",
      "Кол-во слоев: 5\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9549\n",
      "Кол-во слоев: 10\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9619\n",
      "Кол-во слоев: 20\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2876 - accuracy: 0.9241\n",
      "Wall time: 58.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for n in [1, 2, 5, 10, 20]:\n",
    "    print('Кол-во слоев:', n)\n",
    "    create_model(train_images, train_labels, neurons=64, internal_layers=n, epochs=5, verb_param=0, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой-либо связи между кол-вом внутренних слоев и значением метрики качества я не увидел.  Даже значение немного падает с ростом слоев. Возможно, что кол-во слоев важно на более крупных датасетах, и там изменение будет заметней. Или с ростом кол-ва слоев нужно увеличивать и другие параметры - например, кол-во нейронов, кол-во эпох и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Протестируем разное кол-во эпох в моделе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во эпох: 1\n",
      "313/313 [==============================] - 0s 937us/step - loss: 0.2139 - accuracy: 0.9375\n",
      "Кол-во эпох: 5\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.9608\n",
      "Кол-во эпох: 10\n",
      "313/313 [==============================] - 0s 861us/step - loss: 0.1089 - accuracy: 0.9683\n",
      "Кол-во эпох: 20\n",
      "313/313 [==============================] - 0s 837us/step - loss: 0.1313 - accuracy: 0.9672\n",
      "Кол-во эпох: 50\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1781 - accuracy: 0.9731\n",
      "Кол-во эпох: 100\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9743\n",
      "Wall time: 4min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for n in [1, 5, 10, 20, 50, 100]:\n",
    "    print('Кол-во эпох:', n)\n",
    "    create_model(train_images, train_labels, neurons=64, internal_layers=1, epochs=n, verb_param=0, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличение кол-ва эпох существенно влияет на значении метрики качества модели. Скорей всего, здесь есть некий предел, но на протестированных значениях, я его не увидел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Протестируем разные метрики качества в моделе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемая метрика: accuracy\n",
      "313/313 [==============================] - 0s 865us/step - loss: 0.0930 - accuracy: 0.9725\n",
      "Используемая метрика: mse\n",
      "313/313 [==============================] - 0s 934us/step - loss: 0.1088 - mse: 0.0049\n",
      "Используемая метрика: mae\n",
      "313/313 [==============================] - 0s 848us/step - loss: 0.0915 - mae: 0.0070\n",
      "Wall time: 45.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for n in ['accuracy', 'mse', 'mae']:\n",
    "    print('Используемая метрика:', n)\n",
    "    create_model(train_images, train_labels, neurons=64, internal_layers=1, epochs=10, verb_param=0, metric=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку я использовал разные метрики качества, то сложно сказать, как они влияют. Я не уверен, используется ли вообще в обучении указанная метрика качества, или она применяется только для оценки результата..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Поработайте с документацией Keras. Попробуйте найти полезные команды Keras неразобранные на уроке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я решил поиграться с Keras по ее документации https://keras.io/guides/functional_api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 784])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Определяем вид входных данных\n",
    "inputs = keras.Input(shape=(784,))\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определяем первый слой\n",
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "#Подаем входные данные\n",
    "x = dense(inputs)\n",
    "#Определяем второй слой и подаем на вход данные первого слоя\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "#Получаем выходные данные\n",
    "outputs = layers.Dense(10)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Создаем модель с определенными выше параметрами и смотрим, что она из себя представляет\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Загружаем тренировочные и тестовые данные\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выполняем нормализацию и reshape\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.1552 - accuracy: 0.9761\n"
     ]
    }
   ],
   "source": [
    "#Обучаем модель на тренировочных данных и получаем значения ошибки и точности для тестовых\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "#Использоваение параметра verbose со значением 0 позволяет скрыть вывод данных по эпохам и увидеть только итоговый результат\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=3, validation_split=0.2, verbose=0)\n",
    "\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mnist_model',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 784),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'input_1'},\n",
       "   'name': 'input_1',\n",
       "   'inbound_nodes': []},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 64,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'name': 'dense',\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 64,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'name': 'dense_1',\n",
       "   'inbound_nodes': [[['dense', 0, 0, {}]]]},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 10,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'name': 'dense_2',\n",
       "   'inbound_nodes': [[['dense_1', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['dense_2', 0, 0]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Конфигурация модели\n",
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Model\", \"config\": {\"name\": \"mnist_model\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 784], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_1\"}, \"name\": \"input_1\", \"inbound_nodes\": []}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"dense\", \"inbound_nodes\": [[[\"input_1\", 0, 0, {}]]]}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"dense_1\", \"inbound_nodes\": [[[\"dense\", 0, 0, {}]]]}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"dense_2\", \"inbound_nodes\": [[[\"dense_1\", 0, 0, {}]]]}], \"input_layers\": [[\"input_1\", 0, 0]], \"output_layers\": [[\"dense_2\", 0, 0]]}, \"keras_version\": \"2.3.0-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Конфигурация модели в json формате\n",
    "model.to_json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
